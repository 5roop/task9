{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en-sl.deduped.txt\n",
      "Data loading completed.\n",
      "en-hr.deduped.txt\n",
      "Data loading completed.\n",
      "en-bg.deduped.txt\n",
      "Data loading completed.\n",
      "en-mk.deduped.txt\n",
      "Data loading completed.\n",
      "en-is.deduped.txt\n",
      "Data loading completed.\n",
      "en-mt.deduped.txt\n",
      "Data loading completed.\n",
      "en-tr.deduped.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping line 521734: field larger than field limit (262144)\n",
      "Skipping line 1856034: field larger than field limit (262144)\n",
      "Skipping line 2197252: field larger than field limit (262144)\n",
      "Skipping line 3110577: field larger than field limit (262144)\n",
      "Skipping line 5841542: field larger than field limit (262144)\n",
      "Skipping line 8087561: field larger than field limit (262144)\n",
      "Skipping line 20907159: field larger than field limit (262144)\n",
      "Skipping line 25333411: field larger than field limit (262144)\n",
      "Skipping line 30629085: field larger than field limit (262144)\n",
      "Skipping line 32721358: field larger than field limit (262144)\n",
      "Skipping line 36801883: field larger than field limit (262144)\n",
      "Skipping line 37435530: field larger than field limit (262144)\n",
      "Skipping line 38034003: field larger than field limit (262144)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading completed.\n"
     ]
    }
   ],
   "source": [
    "mydatadir = \"/data1/peterr/bilingual_data_for_ABClf\"\n",
    "outdir = \"/data1/peterr/bilingual_data_for_ABClf_output\"\n",
    "import os\n",
    "import pandas as pd\n",
    "from ABClf import load_lexicon, get_variant, count_variants\n",
    "\n",
    "lex = load_lexicon()\n",
    "lex_balanced = load_lexicon(balanced=True)\n",
    "\n",
    "import parse\n",
    "def get_domain(url:str) -> str:\n",
    "    pattern = \"{protocol}://{domain}/{rest}\"\n",
    "    p = parse.compile(pattern)\n",
    "    modified_pattern = \"{protocol}://{domain}/\"\n",
    "    mp = parse.compile(modified_pattern)\n",
    "    try:\n",
    "        parse_result = p.parse(url)\n",
    "        domain = parse_result[\"domain\"]\n",
    "    except TypeError:\n",
    "        parse_result = mp.parse(url)\n",
    "        domain = parse_result[\"domain\"]\n",
    "    return domain\n",
    "\n",
    "\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "csv.field_size_limit(int(131072 * 2))\n",
    "\n",
    "\n",
    "for file in os.listdir(mydatadir):\n",
    "    endpath = os.path.join(\n",
    "            outdir,\n",
    "            file+\"ABClf_output.csv\"\n",
    "        )\n",
    "    # if os.path.basename(endpath) in os.listdir(outdir):\n",
    "    #     continue\n",
    "    if not file.endswith(\".txt\"):\n",
    "        continue\n",
    "    print(file)\n",
    "    from dask import dataframe\n",
    "\n",
    "    df = pd.read_csv(\n",
    "        os.path.join(\n",
    "            mydatadir,\n",
    "            file),\n",
    "        sep=\"\\t\",\n",
    "        engine=\"python\",\n",
    "        quoting=3,\n",
    "        on_bad_lines=\"warn\").iloc[:, [0,2]].dropna()\n",
    "    print(\"Data loading completed.\")\n",
    "    df.columns=[\"url\", \"text\"]\n",
    "\n",
    "    s = df.groupby(\"url\")[\"text\"].apply(\" \".join)\n",
    "    \n",
    "\n",
    "    ndf = pd.DataFrame(s)\n",
    "    # from concurrent.futures import ProcessPoolExecutor\n",
    "    # with ProcessPoolExecutor(max_workers=60) as executor:\n",
    "    #     ndf[\"variant_unbalanced\"] = list(executor.map(lambda s: get_variant(s, lex=lex), ndf.text))\n",
    "    #     ndf[\"per_token_unbalanced\"] = list(executor.map(lambda s: count_variants(s, lex)[1]), ndf.text)\n",
    "    #     ndf[\"variant_balanced\"] = list(executor.map(lambda s: get_variant(s, lex=lex_balanced), ndf.text))\n",
    "    #     ndf[\"per_token_balanced\"] = list(executor.map(lambda s: count_variants(s, lex_balanced)[1]), ndf.text)\n",
    "    #     ndf[\"domain\"] = list(executor.map(get_domain, ndf.index.values))\n",
    "\n",
    "    ndf[\"variant_unbalanced\"] = ndf.text.apply(lambda s: get_variant(s, lex=lex))\n",
    "    ndf[\"per_token_unbalanced\"] = ndf.text.apply(lambda s: count_variants(s, lex)[1])\n",
    "    ndf[\"variant_balanced\"] = ndf.text.apply(lambda s: get_variant(s, lex=lex_balanced))\n",
    "    ndf[\"per_token_balanced\"] = ndf.text.apply(lambda s: count_variants(s, lex_balanced)[1])\n",
    "    ndf[\"domain\"] = [get_domain(url) for url in ndf.index.values]\n",
    "\n",
    "    ndf.to_csv(\n",
    "        endpath\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mydatadir = \"/data1/peterr/bilingual_data_for_ABClf\"\n",
    "f = os.listdir(mydatadir)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask import dataframe\n",
    "df = dataframe.read_csv(os.path.join(\n",
    "                mydatadir, f\n",
    "            ), \n",
    "            sep=\"\\t\",\n",
    "            quoting=3\n",
    "\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7f6f5766036ee03d059e365a942add07f79c17033585e9357ee8157d52fe6bb9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
